
## 目前的摘要生成效果与可能的原因
![[../homework/AIHomework/cache/Pasted image 20221102143152.png]]
### 考虑可能的原因
词典问题，数据量问题，数据集字词准确度问题，模型选择问题
## 数据集处理过程中的问题

1. 在人工处理数据集的过程中发现数据集中有些摘要的质量特别差，应该被剔除掉，或者重新生成摘要。
2. 研究之后发现模型对错字的容忍度其实很低，至少关键词句不能有错，这方面的处理不到位。
3. 有些摘要的内容看上去非常像是抽取式摘要做出来的东西，几乎没有什么修改，在数据量较小的情况下或许可以使用抽取式摘要
4. 有些摘要似乎有着模板化的特征，或许可以借鉴模板化的生成式自动摘要技术。第3，4两点都是基于数据量比较小的情况下，低于万级别的数据集，或许这种方法的生成效果会比深度学习效果要好。
## SPACES的相关问题

![[../images/Pasted image 20221102144332.png]]
法研杯的数据集是比较大的，总量：9484；输入：平均字数 2568，字数标准差 1122，最大字数 13064，最小数字 866；输出：平均字数 283，字数标准差 36，最大字数 474，最小数字 66；
1. 里面也提到了，2000字的文本摘要工作并不是主流研究的应用场景，
2. 另一方面，接近一万的数据集的大小也是很大的，相较而言咱们的数据集总量不到100，就比较小，数据集这方面可能需要 自己主动去搜集一些政论类型的文章
3. SPACES模型的总体思路是先使用序列标注方法进行抽取式摘要生成，然后使用人工摘要结合生成式摘要方法进行进一步的润色。按照这个思路来说，咱们为什么要标注数据集？这个应该是序列标注的任务。这会儿在看这个部分
4. 他们选择的这种抽取+生成的模型，这是针对数据集的特点定制的，这种特点就是“输出跟输入是高度重合的”，而在我们的数据集中有一部分数据是有这种特征的，但不是所有都符合。所以这里可能需要一定的取舍。


## 其他
词典的必要性？词典怎么生成？或者从哪里找？
抽取模型，
下面这个就是我之前在群里说的那个想法，我自己也写了一个，但是效果不是很好。
```
def extract_matching(texts, summaries, start_i=0, start_j=0):  
    """在texts中找若干句子，使得它们连起来与summaries尽可能相似  
    算法：texts和summaries都分句，然后找出summaries最长的句子，在texts  
          中找与之最相似的句子作为匹配，剩下部分递归执行。  
    """    if len(texts) == 0 or len(summaries) == 0:  
        return []  
    i = np.argmax([len(s) for s in summaries])  
    j = np.argmax([compute_main_metric(t, summaries[i], 'char') for t in texts])  
    lm = extract_matching(texts[:j + 1], summaries[:i], start_i, start_j)  
    rm = extract_matching(  
        texts[j:], summaries[i + 1:], start_i + i + 1, start_j + j  
    )  
    return lm + [(start_i + i, start_j + j)] + rm
```